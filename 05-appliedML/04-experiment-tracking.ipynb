{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>ECON 725: Computer Programming and Data Management in Economics <a class=\"tocSkip\"></center>    \n",
    "# <center> MLOps: Experiment Tracking <a class=\"tocSkip\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "<hr>\n",
    "\n",
    "- Understand the importance of experiment tracking in machine learning projects.\n",
    "- Learn how to set up and use experiment tracking tools like Weights and Biases.\n",
    "- Gain hands-on experience in logging experiments, parameters, metrics, and artifacts.\n",
    "- Learn how to compare different experiment runs and select the best model.\n",
    "- Understand how to integrate experiment tracking with other ML tools and workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick introduction to Experiment Tracking with Weights & Biases\n",
    "\n",
    "<center><img width=\"30%\" src=\"img/wandb.png\"/></center>\n",
    "\n",
    "Experiment tracking is the process of recording and monitoring the details of the experiments you run, including the parameters, metrics, and artifacts generated during the training process. This information helps you keep track of the experiments you run, compare different runs, and select the best model based on the performance metrics. \n",
    "\n",
    "In this session, we will use Weights & Biases (W&B) to log and track our machine learning experiments. W&B is a popular experiment tracking tool that allows you to log and visualize your experiments in a collaborative and reproducible way. It provides a unified interface to log various aspects of your experiments, including parameters, metrics, artifacts, and more.\n",
    "\n",
    "# Setting up Weights & Biases\n",
    "\n",
    "To get started with W&B, you need to create an account on the W&B platform and install the W&B library in your Python environment. You can sign up for a free account on the W&B website (https://www.wandb.com/) and follow the instructions to create an account. Ideally, you should use your GitHub account for easy authentication. Once you have created an account, you can install the W&B library using `pip`:\n",
    "\n",
    "```bash\n",
    "pip install wandb\n",
    "```\n",
    "\n",
    "After installing the library, you need to authenticate your account by running the following command in your terminal or notebook:\n",
    "\n",
    "```bash\n",
    "wandb login\n",
    "```\n",
    "\n",
    "This will prompt you to log in to your W&B account and authenticate your session. Once you have authenticated your account, you are ready to start logging your experiments using W&B.\n",
    "\n",
    "\n",
    "<center><img width=\"40%\" src=\"img/wandblogin.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log a Run to a new project\n",
    "\n",
    "Start tracking system metrics and console logs, right out of the box. Run this sample code to see the new run appear in W&B.\n",
    "\n",
    "```python\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "\n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a Weights & Biases Run\n",
    "\n",
    "At the beginning of our script or notebook, calling `wandb.init()` generates a background process to sync and log data as a W&B Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarcelortizv\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/econ725-fall2024/05-appliedML/wandb/run-20241119_013135-8ly1818l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/8ly1818l' target=\"_blank\">experiment-1</a></strong> to <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/8ly1818l' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb/runs/8ly1818l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/marcelortizv/econ725-wandb/runs/8ly1818l?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x75ad93e856a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"econ725-wandb\", name=\"experiment-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Iris dataset\n",
    "\n",
    "We will use the Iris dataset for this example. The Iris dataset is a classic dataset in machine learning and statistics, which contains 150 samples of iris flowers, each with four features (sepal length, sepal width, petal length, and petal width) and a target label (species of iris). In order to know more about this dataset, you can checkout the [official docs for `sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "label_names = [\"Setosa\", \"Versicolour\", \"Virginica\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model and Experiment Tracking\n",
    "\n",
    "Define model configs or other hyperparameters using `wandb.config`. This will automatically track the hyperparameters and output them in the W&B dashboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log your model configs to Weights & Biases\n",
    "params = {\"C\": 0.1, \"random_state\": 42}\n",
    "wandb.config = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and train a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(**params).fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "y_probas = model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log your metrics to Weights & Biases using `wandb.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\n",
    "    \"accuracy\": accuracy_score(y, y_pred),\n",
    "    \"mean_squared_error\": mean_squared_error(y, y_pred)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize and Compare Plots using Weights & Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [**ROC curves**](https://docs.wandb.ai/guides/integrations/scikit#roc) plot true positive rate (y-axis) vs false positive rate (x-axis). The ideal score is a `TPR = 1` and `FPR = 0`, which is the point on the top left. Typically we calculate the area under the ROC curve (AUC-ROC), and the greater the AUC-ROC the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.sklearn.plot_roc(y, y_probas, labels=label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [**precision-recall**](https://docs.wandb.ai/guides/integrations/scikit#precision-recall-curve) curve computes the tradeoff between precision and recall for different thresholds. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall). PR curve is useful when the classes are very imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.sklearn.plot_precision_recall(y, y_probas, labels=label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [**confusion matrix**](https://docs.wandb.ai/guides/integrations/scikit#confusion-matrix) computes the confusion matrix to evaluate the accuracy of a classifier. It's useful for assessing the quality of model predictions and finding patterns in the predictions the model gets wrong. The diagonal represents the predictions the model got right, i.e. where the actual label is equal to the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.sklearn.plot_confusion_matrix(y, y_pred, labels=label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to know more about the different functionalities available as part of the Scikit-Learn integration with Weights & Biases, you can check the [official docs](https://docs.wandb.ai/guides/integrations/scikit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifacts\n",
    "\n",
    "Artifacts are a way to track and version your datasets, models, and other large files. They are a way to track the input and output of your machine learning pipeline. You can log artifacts to W&B using the `wandb.Artifact` class. Artifacts make it easy to get a complete and auditable history of changes to your files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Artifact iris-logistic-regression-model>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save your model\n",
    "with open(\"logistic_regression.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Log your model as a versioned file to Weights & Biases Artifact\n",
    "artifact = wandb.Artifact(f\"iris-logistic-regression-model\", type=\"model\")\n",
    "artifact.add_file(\"logistic_regression.pkl\")\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>mean_squared_error</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.96</td></tr><tr><td>mean_squared_error</td><td>0.04</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment-1</strong> at: <a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/8ly1818l' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb/runs/8ly1818l</a><br/> View project at: <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb</a><br/>Synced 4 W&B file(s), 0 media file(s), 11 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241119_013135-8ly1818l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Finish the run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving Deeper into Weights & Biases\n",
    "\n",
    "Knowing the basic workflow of logging experiments and visualizing the results is just the tip of the iceberg. W&B provides a wide range of features and integrations that can help you streamline your machine learning workflow and collaborate with your team more effectively. Here are some of the key features of W&B:\n",
    "\n",
    "* Versioning datasets using [Artifacts](https://docs.wandb.ai/guides/artifacts).\n",
    "* Exploring and visualizing our datasets with [Tables](https://docs.wandb.ai/guides/tables).\n",
    "* Baseline Experiment with a Random Forest Classification Model.\n",
    "\n",
    "<center><img width=\"40%\" src=\"https://docs.wandb.ai/assets/images/artifacts_landing_page2-a9d45cea4d1c8147231a384b36838619.png\"/></center>\n",
    "\n",
    "<center><img width=\"40%\" src=\"https://docs.wandb.ai/assets/images/tables_sample_predictions-c07d0f6bdee3c0d70b36246af875b878.png\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Dataset to Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `train.csv` and `test.csv` files from [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic/data) and place them in the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/econ725-fall2024/05-appliedML/wandb/run-20241119_023210-cck67rw5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/cck67rw5' target=\"_blank\">ruby-dream-2</a></strong> to <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/cck67rw5' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb/runs/cck67rw5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed58e1d0d9d94039a323ba74550c88cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.090 MB of 0.090 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ruby-dream-2</strong> at: <a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/cck67rw5' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb/runs/cck67rw5</a><br/> View project at: <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb</a><br/>Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241119_023210-cck67rw5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize a WandB Run\n",
    "wandb.init(project=\"econ725-wandb\", job_type=\"log_data\")\n",
    "\n",
    "# Log the `data` directory as an artifact\n",
    "artifact = wandb.Artifact('Titanic', type='dataset', metadata={\"Source\": \"https://www.kaggle.com/competitions/titanic/data\"})\n",
    "artifact.add_dir('data')\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "# End the WandB Run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go to see what happens when we log the dataset to W&B using Artifacts..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versioning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/econ725-fall2024/05-appliedML/wandb/run-20241119_023703-pdnayxrd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/pdnayxrd' target=\"_blank\">sage-fog-3</a></strong> to <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/pdnayxrd' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb/runs/pdnayxrd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "# Initialize a WandB Run\n",
    "wandb.init(project=\"econ725-wandb\", job_type=\"log_data\")\n",
    "\n",
    "# Fetch the dataset artifact \n",
    "artifact = wandb.use_artifact('marcelortizv/econ725-wandb/Titanic:v0', type='dataset')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(artifact_dir, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(artifact_dir, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712 179\n"
     ]
    }
   ],
   "source": [
    "num_train_examples = int(0.8 * len(train_df))\n",
    "num_val_examples = len(train_df) - num_train_examples\n",
    "\n",
    "print(num_train_examples, num_val_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Split\"] = [\"Train\"] * num_train_examples + [\"Validation\"] * num_val_examples\n",
    "train_df.to_csv(\"data/train.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sage-fog-3</strong> at: <a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/pdnayxrd' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb/runs/pdnayxrd</a><br/> View project at: <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241119_023703-pdnayxrd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log the `data` directory as an artifact\n",
    "artifact = wandb.Artifact('Titanic', type='dataset', metadata={\"Source\": \"https://www.kaggle.com/competitions/titanic/data\"})\n",
    "artifact.add_dir('data')\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "# End the WandB Run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/econ725-fall2024/05-appliedML/wandb/run-20241119_024454-tg53y1gh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/tg53y1gh' target=\"_blank\">misty-sun-4</a></strong> to <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/tg53y1gh' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb/runs/tg53y1gh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "# Initialize a WandB Run\n",
    "wandb.init(project=\"econ725-wandb\", job_type=\"explore_data\")\n",
    "\n",
    "# Fetch the latest version of the dataset artifact \n",
    "artifact = wandb.use_artifact('marcelortizv/econ725-wandb/Titanic:latest', type='dataset')\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# Read the files\n",
    "train_val_df = pd.read_csv(os.path.join(artifact_dir, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(artifact_dir, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10a782f0e964bbfa1217eba4d6e64bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.127 MB of 0.127 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-sun-4</strong> at: <a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/tg53y1gh' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb/runs/tg53y1gh</a><br/> View project at: <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb</a><br/>Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241119_024454-tg53y1gh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create tables corresponding to datasets\n",
    "train_val_table = wandb.Table(dataframe=train_val_df)\n",
    "test_table = wandb.Table(dataframe=test_df)\n",
    "\n",
    "# Log the tables to Weights & Biases\n",
    "wandb.log({\n",
    "    \"Train-Val-Table\": train_val_table,\n",
    "    \"Test-Table\": test_table\n",
    "})\n",
    "\n",
    "# End the WandB Run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go to see what happens when we log the dataset to W&B using Artifacts..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/econ725-fall2024/05-appliedML/wandb/run-20241119_025228-uadmbdfy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/uadmbdfy' target=\"_blank\">baseline_experiment-2</a></strong> to <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/uadmbdfy' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb/runs/uadmbdfy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "# Initialize a WandB Run\n",
    "wandb.init(project=\"econ725-wandb\", name=\"baseline_experiment-2\", job_type=\"train\")\n",
    "\n",
    "# Fetch the latest version of the dataset artifact \n",
    "artifact = wandb.use_artifact('marcelortizv/econ725-wandb/Titanic:latest', type='dataset')\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# Read the files\n",
    "train_val_df = pd.read_csv(os.path.join(artifact_dir, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(artifact_dir, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X_train = pd.get_dummies(train_val_df[features][train_val_df[\"Split\"] == \"Train\"])\n",
    "X_val = pd.get_dummies(train_val_df[features][train_val_df[\"Split\"] == \"Validation\"])\n",
    "y_train = train_val_df[\"Survived\"][train_val_df[\"Split\"] == \"Train\"]\n",
    "y_val = train_val_df[\"Survived\"][train_val_df[\"Split\"] == \"Validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\"n_estimators\": 100, \"max_depth\": 10, \"random_state\": 1}\n",
    "wandb.config = model_params\n",
    "\n",
    "model = RandomForestClassifier(**model_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_probas_train = model.predict_proba(X_train)\n",
    "y_pred_val = model.predict(X_val)\n",
    "y_probas_val = model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\n",
    "    \"Train/Accuracy\": accuracy_score(y_train, y_pred_train),\n",
    "    \"Validation/Accuracy\": accuracy_score(y_val, y_pred_val),\n",
    "    \"Train/Presicion\": precision_score(y_train, y_pred_train),\n",
    "    \"Validation/Presicion\": precision_score(y_val, y_pred_val),\n",
    "    \"Train/Recall\": recall_score(y_train, y_pred_train),\n",
    "    \"Validation/Recall\": recall_score(y_val, y_pred_val),\n",
    "    \"Train/F1-Score\": f1_score(y_train, y_pred_train),\n",
    "    \"Validation/F1-Score\": f1_score(y_val, y_pred_val),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.6/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "label_names = [\"Not-Survived\", \"Survived\"]\n",
    "\n",
    "wandb.sklearn.plot_class_proportions(y_train, y_val, label_names)\n",
    "wandb.sklearn.plot_summary_metrics(model, X_train, y_train, X_val, y_val)\n",
    "wandb.sklearn.plot_roc(y_val, y_probas_val, labels=label_names)\n",
    "wandb.sklearn.plot_precision_recall(y_val, y_probas_val, labels=label_names)\n",
    "wandb.sklearn.plot_confusion_matrix(y_val, y_pred_val, labels=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4538420021740a7881a3e333a7ef9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.746 MB of 0.746 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train/Accuracy</td><td>▁</td></tr><tr><td>Train/F1-Score</td><td>▁</td></tr><tr><td>Train/Presicion</td><td>▁</td></tr><tr><td>Train/Recall</td><td>▁</td></tr><tr><td>Validation/Accuracy</td><td>▁</td></tr><tr><td>Validation/F1-Score</td><td>▁</td></tr><tr><td>Validation/Presicion</td><td>▁</td></tr><tr><td>Validation/Recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train/Accuracy</td><td>0.8118</td></tr><tr><td>Train/F1-Score</td><td>0.73307</td></tr><tr><td>Train/Presicion</td><td>0.82143</td></tr><tr><td>Train/Recall</td><td>0.66187</td></tr><tr><td>Validation/Accuracy</td><td>0.82123</td></tr><tr><td>Validation/F1-Score</td><td>0.72881</td></tr><tr><td>Validation/Presicion</td><td>0.7963</td></tr><tr><td>Validation/Recall</td><td>0.67188</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">baseline_experiment-2</strong> at: <a href='https://wandb.ai/marcelortizv/econ725-wandb/runs/uadmbdfy' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb/runs/uadmbdfy</a><br/> View project at: <a href='https://wandb.ai/marcelortizv/econ725-wandb' target=\"_blank\">https://wandb.ai/marcelortizv/econ725-wandb</a><br/>Synced 5 W&B file(s), 0 media file(s), 14 artifact file(s) and 5 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241119_025228-uadmbdfy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your model\n",
    "with open(\"random_forest_classifier.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Log your model as a versioned file to Weights & Biases Artifact\n",
    "artifact = wandb.Artifact(f\"titanic-random-forest-model\", type=\"model\")\n",
    "artifact.add_file(\"random_forest_classifier.pkl\")\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "\n",
    "# End the WandB Run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization with Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in Terminal\n",
    "# python 04_1_hyperparameter_tuning.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img width=\"80%\" src=\"img/sweep.png\"/></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
